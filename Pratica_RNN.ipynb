{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "114dfb66-c145-46de-81ca-3ae2148dc947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20ed2677-eb64-437a-b34e-198b6330f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = \"O Yan vai tirar 10 na avaliação, pois ele conseguiu colar na prova\"\n",
    "frase_dividida = dados.split()\n",
    "\n",
    "tokenizer = Tokenizer(oov_token ='<unk>')\n",
    "tokenizer.fit_on_texts([frase_dividida])\n",
    "indices_palavras = tokenizer.word_index\n",
    "vocab_tamanho =  len(indices_palavras)+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae83874f-2175-4661-8640-5cbab5588510",
   "metadata": {},
   "outputs": [],
   "source": [
    "entradas = []\n",
    "saida = []\n",
    "\n",
    "for i in range(1, len(frase_dividida)):\n",
    "    sequencia = frase_dividida[:i+1]\n",
    "    entradas.append(sequencia[:-1])\n",
    "    saida.append(sequencia[-1])\n",
    "\n",
    "sequencias_entradas = tokenizer.texts_to_sequences(entradas)\n",
    "sequencias_saidas = tokenizer.texts_to_sequences(saida)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a57682c-884d-4347-944f-577457f3cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tamanho_seq = max([len(x) for x in sequencias_entradas])\n",
    "sequencias_entradas = tf.keras.preprocessing.sequence.pad_sequences(sequencias_entradas,maxlen = max_tamanho_seq, padding = 'pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94d1bbf5-6ec2-4fbd-b0d1-417b233bfaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathe\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "modelo = Sequential()\n",
    "modelo.add(Embedding(input_dim = vocab_tamanho, output_dim = 10, input_length = max_tamanho_seq))\n",
    "\n",
    "modelo.add(LSTM(100, return_sequences = True))\n",
    "modelo.add(Dropout(0.3))\n",
    "\n",
    "modelo.add(LSTM(100))\n",
    "modelo.add(Dropout(0.3))\n",
    "\n",
    "modelo.add(Dense(50, activation = 'relu'))\n",
    "\n",
    "modelo.add(Dense(vocab_tamanho, activation = 'softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bcf3e61-b4d9-41d4-aa25-7e0ac0765e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2569aec70d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.compile(optimizer = 'nadam', loss ='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "modelo.fit(sequencias_entradas, np.array(sequencias_saidas), epochs = 400, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a09c82a-dacd-4406-be0c-a6831df222b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prever_proxima_palavra(modelo, tokenizer, sequencia_entrada,max_tamanho):\n",
    "    sequencia_num = tokenizer.texts_to_sequences([sequencia_entrada])\n",
    "    sequencia_num = tf.keras.preprocessing.sequence.pad_sequences(sequencia_num, maxlen=max_tamanho, padding='pre')\n",
    "    \n",
    "    predicao = modelo.predict(sequencia_num)\n",
    "    indice_predito = np.argmax(predicao, axis=-1)\n",
    "    \n",
    "    indice_para_palavra = dict([(value, key) for (key, value) in tokenizer.word_index.items()])\n",
    "    \n",
    "    return indice_para_palavra.get(indice_predito[0], '<unk>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fec0dc32-e1a3-44c6-9a56-9c1a06cecb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "\n",
      "Frase de entrada: 'O Yan vai tirar 10 na avaliação, pois ele conseguiu '\n",
      "Próxima palavra prevista: 'colar'\n"
     ]
    }
   ],
   "source": [
    "frase_teste = \"O Yan vai tirar 10 na avaliação, pois ele conseguiu \"\n",
    "palavra_predita = prever_proxima_palavra(modelo, tokenizer, frase_teste, max_tamanho_seq)\n",
    "print(f\"\\nFrase de entrada: '{frase_teste}'\")\n",
    "print(f\"Próxima palavra prevista: '{palavra_predita}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
